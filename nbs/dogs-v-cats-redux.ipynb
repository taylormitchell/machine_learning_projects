{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats: Redux Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model for submission into the the Dogs vs Cats Redux Kaggle Competition:\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "\n",
    "The final model is a finetuned version of a pre-trained VGG16 model which made it into the top 40% of the public leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "DATA_DIR = HOME_DIR + '/data/dogs-vs-cats'\n",
    "TEST_DIR = DATA_DIR+'/test'\n",
    "TRAIN_DIR = DATA_DIR+'/train'\n",
    "VALID_DIR = DATA_DIR+'/valid'\n",
    "MODEL_DIR = DATA_DIR+'/models'\n",
    "# sample of training data\n",
    "SAMPLE_DIR = DATA_DIR+'/sample'\n",
    "SAMPLE_TRAIN_DIR = SAMPLE_DIR + '/train'\n",
    "SAMPLE_VALID_DIR = SAMPLE_DIR + '/valid'\n",
    "IMG_SHAPE = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_sample = 80\n",
    "nb_valid_sample = 20\n",
    "nb_valid = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a folder for the data in the current working directory, download the kaggle dataset using the kaggle API and extract the training and test files into the data directory. \n",
    "\n",
    "You can also download the data from the kaggle page:<br>\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
    "\n",
    "If you download it yourself, make sure to place the train and test images in folders corresponding with TEST_DIR and TRAIN_DIR defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $DATA_DIR\n",
    "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q $DATA_DIR/test.zip -d $DATA_DIR\n",
    "!unzip -q $DATA_DIR/train.zip -d $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into testing, training, and validation. I also copy a small random sample from the training set for initial experimentation. These examples are placed in the sample folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [TRAIN_DIR, VALID_DIR, SAMPLE_TRAIN_DIR, SAMPLE_VALID_DIR]:\n",
    "    %mkdir -p $path/dogs\n",
    "    %mkdir -p $path/cats\n",
    "%mkdir -p $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data_to_subdirs(train_dir):\n",
    "    sub_dirs = [f.path for f in os.scandir(TRAIN_DIR) if f.is_dir()]\n",
    "    for sub_dir in sub_dirs:\n",
    "        # Category which matches this sub-directory\n",
    "        category = os.path.basename(sub_dir)[:-1]\n",
    "        # Paths for files to move to sub-directory\n",
    "        file_paths = glob(os.path.join(train_dir, category + '.*'))\n",
    "        for path_original in file_paths:\n",
    "            filename = os.path.basename(path_original)\n",
    "            path_new = os.path.join(sub_dir, filename)\n",
    "            os.rename(path_original, path_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_data_to_subdirs(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(train_dir, sample_dir, nb_train, nb_valid):\n",
    "    sub_dirs = os.listdir(train_dir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        file_paths = glob(os.path.join(train_dir, sub_dir, '*.jpg'))\n",
    "        np.random.permutation(file_paths) #shuffle files\n",
    "        # Move some to the sample train folder\n",
    "        for i in range(nb_train): \n",
    "            filename = os.path.basename(file_paths[i])\n",
    "            destination = os.path.join(sample_dir, 'train', sub_dir, filename)\n",
    "            copyfile(file_paths[i], destination)\n",
    "        # Move some to the sample valid folder\n",
    "        for i in range(nb_train, nb_train+nb_valid): \n",
    "            filename = os.path.basename(file_paths[i])\n",
    "            destination = os.path.join(sample_dir, 'valid', sub_dir, filename)\n",
    "            copyfile(file_paths[i], destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sample(TRAIN_DIR, SAMPLE_DIR, nb_train_sample, nb_valid_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_valid(train_dir, valid_dir, nb_valid):\n",
    "    sub_dirs = os.listdir(train_dir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        file_paths = glob(os.path.join(train_dir, sub_dir, '*.jpg'))\n",
    "        np.random.permutation(file_paths) #shuffle files\n",
    "        # Move some to the sample train folder\n",
    "        for i in range(nb_valid):\n",
    "            filename = os.path.basename(file_paths[i])\n",
    "            dest = os.path.join(valid_dir, sub_dir, filename)\n",
    "            os.rename(file_paths[i], dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_to_valid(TRAIN_DIR, VALID_DIR, nb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gen(directory, batch_size=4, shuffle=True, \n",
    "               gen=ImageDataGenerator(), target_size=(224,224), \n",
    "               class_mode = None):\n",
    "    return gen.flow_from_directory(directory,\n",
    "                                   batch_size = batch_size,\n",
    "                                   shuffle = shuffle,\n",
    "                                   target_size = target_size, \n",
    "                                   class_mode = class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data genererators\n",
    "batch_size = 64\n",
    "sample_train_gen = create_gen(SAMPLE_TRAIN_DIR, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "sample_valid_gen = create_gen(SAMPLE_VALID_DIR, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "train_gen = create_gen(TRAIN_DIR, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "valid_gen = create_gen(VALID_DIR, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "test_gen = create_gen(TEST_DIR, batch_size=batch_size, shuffle=True, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        img = np.rollaxis(img,0,3).astype(np.uint8)\n",
    "    else:\n",
    "        img = np.rollaxis(img,0,1).astype(np.uint8)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first models tried here are meant to serve as benchmarks to compare later models to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The model's accuracy on the training data steadily increases, so we know we're learning something. But looking at the validation accuracy, it looks like it's fluctuating around 50 percent, no better than guessing. So the model is fitting the training data but isn't generalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=IMG_SHAPE))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 5s - loss: 6.0550 - acc: 0.4859 - val_loss: 7.6444 - val_acc: 0.5000\n",
      "Epoch 2/8\n",
      " - 5s - loss: 5.9200 - acc: 0.5930 - val_loss: 7.8531 - val_acc: 0.4500\n",
      "Epoch 3/8\n",
      " - 5s - loss: 6.4399 - acc: 0.5633 - val_loss: 9.4186 - val_acc: 0.4000\n",
      "Epoch 4/8\n",
      " - 5s - loss: 6.3739 - acc: 0.5898 - val_loss: 9.1734 - val_acc: 0.4000\n",
      "Epoch 5/8\n",
      " - 5s - loss: 6.3072 - acc: 0.5656 - val_loss: 7.0310 - val_acc: 0.5250\n",
      "Epoch 6/8\n",
      " - 5s - loss: 5.0085 - acc: 0.6664 - val_loss: 6.1718 - val_acc: 0.5500\n",
      "Epoch 7/8\n",
      " - 5s - loss: 4.6386 - acc: 0.6953 - val_loss: 5.6401 - val_acc: 0.6250\n",
      "Epoch 8/8\n",
      " - 5s - loss: 4.6860 - acc: 0.6711 - val_loss: 6.3744 - val_acc: 0.5750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfe2165748>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(sample_train_gen, epochs=8, validation_data=sample_valid_gen, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Same issue as the model above. We can start to fit to the training data, but it's not generalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=IMG_SHAPE))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3/3 [==============================] - 7s 2s/step - loss: 2.8218 - acc: 0.5602 - val_loss: 2.6976 - val_acc: 0.5250\n",
      "Epoch 2/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 2.9911 - acc: 0.6547 - val_loss: 2.0940 - val_acc: 0.5000\n",
      "Epoch 3/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 2.5883 - acc: 0.6359 - val_loss: 1.7685 - val_acc: 0.5500\n",
      "Epoch 4/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.9585 - acc: 0.6422 - val_loss: 1.5388 - val_acc: 0.5750\n",
      "Epoch 5/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.3437 - acc: 0.5945 - val_loss: 1.4042 - val_acc: 0.5250\n",
      "Epoch 6/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8996 - acc: 0.6859 - val_loss: 1.3383 - val_acc: 0.5750\n",
      "Epoch 7/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7167 - acc: 0.6984 - val_loss: 1.2498 - val_acc: 0.5250\n",
      "Epoch 8/8\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.5617 - acc: 0.6953 - val_loss: 1.0749 - val_acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfe1de6358>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(sample_train_gen, epochs=8, validation_data=sample_valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shallow CNN has the same issue as the last two models. I try making it deeper, but it doesn't look like it's enough for it to learn anything useful. <br>Next I'll try a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = Sequential()\n",
    "cnn1.add(BatchNormalization(axis=1, input_shape = IMG_SHAPE))\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(100))\n",
    "cnn1.add(BatchNormalization())\n",
    "cnn1.add(Dense(1,activation = 'sigmoid'))\n",
    "cnn1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "cnn1.fit_generator(sample_train_gen, epochs=4, validation_data=sample_valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential()\n",
    "cnn1.add(BatchNormalization(axis=1, input_shape = img_shape))\n",
    "# Block 1\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "# Block 2\n",
    "cnn1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "# Block 4\n",
    "cnn1.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "# Top\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(256))\n",
    "cnn1.add(BatchNormalization())\n",
    "cnn1.add(Dense(1,activation = 'sigmoid'))\n",
    "cnn1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "3/3 [==============================] - 15s 5s/step - loss: 2.9895 - acc: 0.6008 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/4\n",
      "3/3 [==============================] - 14s 5s/step - loss: 3.4410 - acc: 0.6781 - val_loss: 7.5753 - val_acc: 0.5000\n",
      "Epoch 3/4\n",
      "3/3 [==============================] - 14s 5s/step - loss: 2.9601 - acc: 0.6781 - val_loss: 1.3932 - val_acc: 0.4500\n",
      "Epoch 4/4\n",
      "3/3 [==============================] - 14s 5s/step - loss: 2.1013 - acc: 0.6969 - val_loss: 2.8407 - val_acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb894312e50>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit_generator(sample_train_gen, epochs=4, validation_data=sample_valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FINETUNED VGG16 MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create VGG16 pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create VGG16 model and load it with weights trained from imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "nb_epochs=3\n",
    "nb_sample_train = 160\n",
    "nb_sample_valid = 40\n",
    "nb_train = 20000\n",
    "nb_valid = 5000\n",
    "\n",
    "bn_feat_sample_train = 'bn_feat_sample_train.npy'\n",
    "bn_feat_sample_valid = 'bn_feat_sample_valid.npy'\n",
    "bn_feat_train = 'bn_feat_train.npy'\n",
    "bn_feat_valid = 'bn_feat_valid.npy'\n",
    "bn_feat_test = 'bn_feat_test.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compute VGG16 bottleneck features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's where I compute the bottleneck features. These are the outputs from the last convolutional block of VGG16 which would feed into the dense layers on top (which we didn't include). The VGG16 convolutional layers are very good at pulling out useful features from images. With the top included, VGG16 would then take these features, and output an imagenet class. So the convolutional layers pull out useful features from images, and the dense layers use these features to determine what the image is. We're going to keep these features that the VGG16 pulls out of our dataset, and then use those to train a new network to classify them as either cats or dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create generators\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1., featurewise_center=True) #(rescale=1./255)\n",
    "datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3) #3,1,1\n",
    "\n",
    "sample_train_gen = create_gen(sample_train_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "sample_valid_gen = create_gen(sample_valid_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "train_gen = create_gen(train_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "valid_gen = create_gen(valid_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "test_gen = create_gen(test_dir, batch_size=batch_size, shuffle=False, gen=datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create sample train data bottleneck features\n",
    "bottleneck_features_train = model.predict_generator(sample_train_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_sample_train, 'w'),\n",
    "        bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create sample validation data bottleneck features\n",
    "bottleneck_features_valid = model.predict_generator(sample_valid_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_sample_valid, 'w'),bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create train data bottleneck features\n",
    "bottleneck_features_train = model.predict_generator(test_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_train, 'w'),bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create valid data bottleneck features\n",
    "bottleneck_features_valid = model.predict_generator(valid_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_valid, 'w'),bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# create test data bottleneck features\n",
    "bottleneck_features_test = model.predict_generator(test_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_test, 'w'), bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load VGG16 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load the saved VGG features. There are two cells here, one for training on the full training set, and one for training only on the small sample data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Full training set of features and labels\n",
    "test_features = np.load(open(saved_model_dir + bn_feat_test))\n",
    "train_features = np.load(open(saved_model_dir + bn_feat_train))\n",
    "valid_features = np.load(open(saved_model_dir + bn_feat_valid))\n",
    "train_labels = np.array([1] * int(nb_train / 2) + [0] * int(nb_train / 2))\n",
    "valid_labels = np.array([1] * int(nb_valid / 2) + [0] * int(nb_valid / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Small sample set of features and labels\n",
    "# train_features = np.load(open(saved_model_dir + bn_feat_sample_train))\n",
    "# valid_features = np.load(open(saved_model_dir + bn_feat_sample_valid))\n",
    "# train_labels = np.array([1] * int(nb_sample_train / 2) + [0] * int(nb_sample_train / 2))\n",
    "# valid_labels = np.array([1] * int(nb_sample_valid / 2) + [0] * int(nb_sample_valid / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Linear model on VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model is just a single linear layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc1 = Sequential()\n",
    "model_fc1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_fc1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_fc1.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 0.6293 - acc: 0.9494 - val_loss: 0.6063 - val_acc: 0.9528\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 0.3472 - acc: 0.9748 - val_loss: 0.3820 - val_acc: 0.9720\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 0.3231 - acc: 0.9762 - val_loss: 0.4282 - val_acc: 0.9690\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 0.2989 - acc: 0.9786 - val_loss: 0.3564 - val_acc: 0.9744\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.2677 - acc: 0.9811 - val_loss: 0.3521 - val_acc: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb892db4050>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_weights = 'best_weights_fc1.h5'\n",
    "checkpointer = ModelCheckpoint(filepath= saved_model_dir + fc1_weights, \n",
    "                               save_best_only=True)\n",
    "\n",
    "model_fc1.fit(train_features,train_labels,\n",
    "              epochs=5,#nb_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(valid_features,valid_labels),\n",
    "              callbacks=[checkpointer],\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12561574509888887"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log loss on validation set\n",
    "model_fc1.load_weights(saved_model_dir + fc1_weights)\n",
    "pred = model_fc1.predict(valid_features)\n",
    "pred = pred.reshape(pred.shape[0])\n",
    "predictions = pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Final model on VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc3 = Sequential()\n",
    "model_fc3.add(MaxPooling2D((2, 2), strides=(2, 2), input_shape=train_features.shape[1:]))\n",
    "model_fc3.add(Flatten())\n",
    "model_fc3.add(Dense(4096, activation='relu'))\n",
    "model_fc3.add(BatchNormalization())\n",
    "model_fc3.add(Dropout(0.5))\n",
    "model_fc3.add(Dense(4096, activation='relu'))\n",
    "model_fc3.add(BatchNormalization())\n",
    "model_fc3.add(Dropout(0.5))\n",
    "model_fc3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_fc3.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 14s 693us/step - loss: 0.2223 - acc: 0.9534 - val_loss: 0.1175 - val_acc: 0.9702\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 14s 697us/step - loss: 0.0821 - acc: 0.9733 - val_loss: 0.0818 - val_acc: 0.9752\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 12s 587us/step - loss: 0.0543 - acc: 0.9829 - val_loss: 0.0824 - val_acc: 0.9778\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 12s 586us/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.1124 - val_acc: 0.9766\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 12s 585us/step - loss: 0.0350 - acc: 0.9904 - val_loss: 0.0892 - val_acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8911c9bd0>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc3_weights = 'best_weights_fc3.h5'\n",
    "checkpointer = ModelCheckpoint(filepath= saved_model_dir + fc3_weights, \n",
    "                               save_best_only=True)\n",
    "\n",
    "model_fc3.fit(train_features,train_labels,\n",
    "              epochs=5,#nb_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(valid_features,valid_labels),\n",
    "              callbacks=[checkpointer],\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Doesn't look like we're seeing much improvement on the loss function after a few epochs. We'd probably need to tweak some hyperparameters or the architecture to improve much from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10920777253806591"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log loss on validation set\n",
    "model_fc3.load_weights(saved_model_dir + fc3_weights)\n",
    "pred = model_fc3.predict(valid_features)\n",
    "pred = pred.reshape(pred.shape[0])\n",
    "predictions = pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like it's an improvement on the linear model above. It's surprising how well the linear model did though. Let's try an ensemble of this model next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    \n",
    "    def __init__(self, nb_models = 3):\n",
    "        self.nb_models = nb_models\n",
    "    \n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2), input_shape=train_features.shape[1:]))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self,epochs=3):\n",
    "        for i in range(self.nb_models):\n",
    "            \n",
    "            weights = 'best_weights_fc3_'+str(i)+'.h5'\n",
    "            checkpointer = ModelCheckpoint(filepath= saved_model_dir + weights, \n",
    "                                           save_best_only=True)\n",
    "            model = self.create_model()\n",
    "            model.fit(train_features,train_labels,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data=(valid_features,valid_labels),\n",
    "                          callbacks=[checkpointer],\n",
    "                          verbose=1)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        preds = []\n",
    "        model = self.create_model()\n",
    "        for i in range(self.nb_models):\n",
    "            model.load_weights(saved_model_dir + 'best_weights_fc3_'+str(i)+'.h5')\n",
    "            preds.append(model.predict(x))\n",
    "        ens_pred = np.stack(preds).mean(axis=0)\n",
    "        return ens_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_ens = Ensemble(3)\n",
    "model_ens.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097072397928684953"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log log on validation set\n",
    "ens_pred = model_ens.predict(valid_features)\n",
    "ens_pred = ens_pred.reshape(ens_pred.shape[0])\n",
    "predictions = ens_pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 687us/step - loss: 0.2133 - acc: 0.9523 - val_loss: 0.0934 - val_acc: 0.9748\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 12s 575us/step - loss: 0.0794 - acc: 0.9747 - val_loss: 0.1409 - val_acc: 0.9692\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 14s 700us/step - loss: 0.0523 - acc: 0.9847 - val_loss: 0.0838 - val_acc: 0.9776\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 680us/step - loss: 0.2159 - acc: 0.9535 - val_loss: 0.1117 - val_acc: 0.9740\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 691us/step - loss: 0.0863 - acc: 0.9727 - val_loss: 0.0786 - val_acc: 0.9756\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 12s 581us/step - loss: 0.0552 - acc: 0.9824 - val_loss: 0.0822 - val_acc: 0.9784\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 685us/step - loss: 0.1971 - acc: 0.9561 - val_loss: 0.1593 - val_acc: 0.9646\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 686us/step - loss: 0.0835 - acc: 0.9734 - val_loss: 0.1225 - val_acc: 0.9692\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 14s 694us/step - loss: 0.0573 - acc: 0.9829 - val_loss: 0.0972 - val_acc: 0.9766\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 690us/step - loss: 0.2227 - acc: 0.9535 - val_loss: 0.5524 - val_acc: 0.8822\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 692us/step - loss: 0.0855 - acc: 0.9724 - val_loss: 0.0756 - val_acc: 0.9782\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 12s 583us/step - loss: 0.0512 - acc: 0.9843 - val_loss: 0.0993 - val_acc: 0.9710\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 687us/step - loss: 0.2320 - acc: 0.9511 - val_loss: 0.1360 - val_acc: 0.9684\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 691us/step - loss: 0.0854 - acc: 0.9724 - val_loss: 0.1007 - val_acc: 0.9728\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 14s 701us/step - loss: 0.0583 - acc: 0.9812 - val_loss: 0.0872 - val_acc: 0.9742\n"
     ]
    }
   ],
   "source": [
    "model_ens = Ensemble(5)\n",
    "model_ens.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0926154362514615"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log log on validation set\n",
    "ens_pred = model_ens.predict(valid_features)\n",
    "ens_pred = ens_pred.reshape(ens_pred.shape[0])\n",
    "predictions = ens_pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As usual, an ensemble tends to do better. Adding more models seems to continue the trend. We could also try an ensemble of different types of models, perhaps using different pre-trained model architectures. I think this should be enough to get into the top 40% of the kaggle competition though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "iscat_pred = model_ens.predict(test_features)\n",
    "predictions = (1 - iscat_pred).reshape(iscat_pred.shape[0])\n",
    "predictions = predictions.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get file indices\n",
    "generator = create_gen(test_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "filenames = generator.filenames\n",
    "idx = np.array([int(f[5:f.rfind('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/dogs-v-cats-redux\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "subm = np.stack([idx,predictions],axis=1)\n",
    "submission_file_name = 'submission3.csv'\n",
    "%cd ~/git/dogs-v-cats-redux\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
