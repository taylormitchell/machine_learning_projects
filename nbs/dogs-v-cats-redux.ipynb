{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DOGS VS CATS REDUX: KERNEL EDITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "My model for submission into the the Dogs vs Cats Redux Kaggle Competition:\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "\n",
    "The final model is a finetuned version of a pre-trained VGG16 model which made it into the top 40% of the public leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Imports, helper functions, and data directory definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from matplotlib import pyplot as plt\n",
    "from shutil import copyfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        img = np.rollaxis(img,0,3).astype(np.uint8)\n",
    "    else:\n",
    "        img = np.rollaxis(img,0,1).astype(np.uint8)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_gen(directory, batch_size=4, shuffle=True, \n",
    "               gen=ImageDataGenerator(), target_size=(224,224), \n",
    "               class_mode = None):\n",
    "    return gen.flow_from_directory(directory,\n",
    "                                   batch_size = batch_size,\n",
    "                                   shuffle = shuffle,\n",
    "                                   target_size = target_size, \n",
    "                                   class_mode = class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "%cd ~/nbs\n",
    "current_dir = os.getcwd()\n",
    "HOME_DIR = current_dir\n",
    "DATA_DIR = HOME_DIR+'/data/dogscats/'\n",
    "\n",
    "test_dir = DATA_DIR+'test/'\n",
    "saved_model_dir = DATA_DIR+'saved_models/'\n",
    "\n",
    "# sample of training data\n",
    "sample_train_dir = DATA_DIR+'sample/train/'\n",
    "sample_valid_dir = DATA_DIR+'sample/valid/'\n",
    "\n",
    "# full training data\n",
    "train_dir = DATA_DIR+'train/'\n",
    "valid_dir = DATA_DIR+'valid/'\n",
    "\n",
    "img_shape = (224,224,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## SPLIT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get data from here:\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
    "\n",
    "I start by splitting the data into testing, training, and validation. I also copy a small random sample from the training set for initial experimentation. These examples are placed in the sample folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create separate folders for train, valid, and sample/train, sample/valid\n",
    "%mkdir -p $DATA_DIR/test/test\n",
    "%mkdir -p $DATA_DIR/train/dogs\n",
    "%mkdir -p $DATA_DIR/train/cats\n",
    "%mkdir -p $DATA_DIR/valid/dogs\n",
    "%mkdir -p $DATA_DIR/valid/cats\n",
    "%mkdir -p $DATA_DIR/sample/train/dogs\n",
    "%mkdir -p $DATA_DIR/sample/train/cats\n",
    "%mkdir -p $DATA_DIR/sample/valid/dogs\n",
    "%mkdir -p $DATA_DIR/sample/valid/cats\n",
    "%mkdir -p $saved_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/ubuntu/nbs/data/dogscats/\u001b[00m\n",
      "├── \u001b[01;34msample\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   │   ├── \u001b[01;34mcats\u001b[00m\n",
      "│   │   └── \u001b[01;34mdogs\u001b[00m\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\n",
      "│       ├── \u001b[01;34mcats\u001b[00m\n",
      "│       └── \u001b[01;34mdogs\u001b[00m\n",
      "├── \u001b[01;34msaved_models\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   └── \u001b[01;34mtest\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mcats\u001b[00m\n",
      "│   └── \u001b[01;34mdogs\u001b[00m\n",
      "└── \u001b[01;34mvalid\u001b[00m\n",
      "    ├── \u001b[01;34mcats\u001b[00m\n",
      "    └── \u001b[01;34mdogs\u001b[00m\n",
      "\n",
      "16 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Move training examples to cats/dogs subdirectories\n",
    "%cd $train_dir\n",
    "from glob import glob\n",
    "c = glob('cat.*')\n",
    "for fname in c: os.rename(fname, DATA_DIR+'/train/cats/'+fname)\n",
    "d = glob('dog.*')\n",
    "for fname in d: os.rename(fname, DATA_DIR+'/train/dogs/'+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Copy some cat and dog examples into the sample folder\n",
    "%cd $train_dir/cats\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(80): copyfile(shuf[i], DATA_DIR+'/sample/train/cats/'+shuf[i])\n",
    "for i in range(80,100): copyfile(shuf[i], DATA_DIR+'/sample/valid/cats/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_DIR/train/dogs\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(80): copyfile(shuf[i], DATA_DIR+'/sample/train/dogs/'+shuf[i])\n",
    "for i in range(80,100): copyfile(shuf[i], DATA_DIR+'/sample/valid/dogs/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/dogscats/train/cats\n"
     ]
    }
   ],
   "source": [
    "# Move random subset of training examples to valid directory\n",
    "%cd $train_dir/cats\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2500): os.rename(shuf[i],DATA_DIR+'/valid/cats/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/dogscats/train/dogs\n"
     ]
    }
   ],
   "source": [
    "%cd $train_dir/dogs\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2500): os.rename(shuf[i],DATA_DIR+'/valid/dogs/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data genererators\n",
    "batch_size = 64\n",
    "sample_train_gen = create_gen(sample_train_dir, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "sample_valid_gen = create_gen(sample_valid_dir, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "train_gen = create_gen(train_dir, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "valid_gen = create_gen(valid_dir, batch_size=batch_size, shuffle=True, class_mode='binary')\n",
    "test_gen = create_gen(test_dir, batch_size=batch_size, shuffle=True, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## BASELINE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first models tried here are meant to serve as benchmarks to compare later models to. The models I try here are Linear, Simple Neural Network, and a Simple CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This one starts to fit to the data but it doesn't generalizing very well. We can see this from the quick increase in the training accuracy while the validation accuracy doesn't look like it's going anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=img_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " - 1s - loss: 0.4671 - acc: 0.7711 - val_loss: 0.6582 - val_acc: 0.5750\n",
      "Epoch 2/4\n",
      " - 1s - loss: 0.4156 - acc: 0.8602 - val_loss: 0.6431 - val_acc: 0.5500\n",
      "Epoch 3/4\n",
      " - 1s - loss: 0.3980 - acc: 0.8734 - val_loss: 0.6370 - val_acc: 0.5500\n",
      "Epoch 4/4\n",
      " - 1s - loss: 0.3557 - acc: 0.9062 - val_loss: 0.6436 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb800557c10>"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(sample_train_gen, epochs=4, validation_data=sample_valid_gen, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Same issue as the model above. We can start to overfit it to the data, but it's not generalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(224,224,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.5934 - acc: 0.6930 - val_loss: 0.6007 - val_acc: 0.6000\n",
      "Epoch 2/4\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.5417 - acc: 0.7742 - val_loss: 0.6162 - val_acc: 0.6250\n",
      "Epoch 3/4\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.5145 - acc: 0.7680 - val_loss: 0.6147 - val_acc: 0.6250\n",
      "Epoch 4/4\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.4805 - acc: 0.8008 - val_loss: 0.6163 - val_acc: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb89acf4490>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(sample_train_gen, epochs=4, validation_data=sample_valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The shallow CNN has the same issue as the last two. I try making it deeper, but it doesn't look like it's enough for it to learn anything useful. <br>Next I'll try a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential()\n",
    "cnn1.add(BatchNormalization(axis=1, input_shape = img_shape))\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(100))\n",
    "cnn1.add(BatchNormalization())\n",
    "cnn1.add(Dense(1,activation = 'sigmoid'))\n",
    "cnn1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.4746 - acc: 0.6070 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/4\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.8874 - acc: 0.7078 - val_loss: 6.2612 - val_acc: 0.6000\n",
      "Epoch 3/4\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.3439 - acc: 0.7703 - val_loss: 8.6762 - val_acc: 0.4500\n",
      "Epoch 4/4\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8355 - acc: 0.7555 - val_loss: 6.3318 - val_acc: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8a27c8f50>"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit_generator(sample_train_gen, epochs=4, validation_data=sample_valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential()\n",
    "cnn1.add(BatchNormalization(axis=1, input_shape = img_shape))\n",
    "# Block 1\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "# Block 2\n",
    "cnn1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "# Block 4\n",
    "cnn1.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "cnn1.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "# Top\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(256))\n",
    "cnn1.add(BatchNormalization())\n",
    "cnn1.add(Dense(1,activation = 'sigmoid'))\n",
    "cnn1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "3/3 [==============================] - 15s 5s/step - loss: 2.9895 - acc: 0.6008 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/4\n",
      "3/3 [==============================] - 14s 5s/step - loss: 3.4410 - acc: 0.6781 - val_loss: 7.5753 - val_acc: 0.5000\n",
      "Epoch 3/4\n",
      "3/3 [==============================] - 14s 5s/step - loss: 2.9601 - acc: 0.6781 - val_loss: 1.3932 - val_acc: 0.4500\n",
      "Epoch 4/4\n",
      "3/3 [==============================] - 14s 5s/step - loss: 2.1013 - acc: 0.6969 - val_loss: 2.8407 - val_acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb894312e50>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit_generator(sample_train_gen, epochs=4, validation_data=sample_valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## FINETUNED VGG16 MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create VGG16 pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create VGG16 model and load it with weights trained from imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "nb_epochs=3\n",
    "nb_sample_train = 160\n",
    "nb_sample_valid = 40\n",
    "nb_train = 20000\n",
    "nb_valid = 5000\n",
    "\n",
    "bn_feat_sample_train = 'bn_feat_sample_train.npy'\n",
    "bn_feat_sample_valid = 'bn_feat_sample_valid.npy'\n",
    "bn_feat_train = 'bn_feat_train.npy'\n",
    "bn_feat_valid = 'bn_feat_valid.npy'\n",
    "bn_feat_test = 'bn_feat_test.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compute VGG16 bottleneck features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's where I compute the bottleneck features. These are the outputs from the last convolutional block of VGG16 which would feed into the dense layers on top (which we didn't include). The VGG16 convolutional layers are very good at pulling out useful features from images. With the top included, VGG16 would then take these features, and output an imagenet class. So the convolutional layers pull out useful features from images, and the dense layers use these features to determine what the image is. We're going to keep these features that the VGG16 pulls out of our dataset, and then use those to train a new network to classify them as either cats or dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create generators\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1., featurewise_center=True) #(rescale=1./255)\n",
    "datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3) #3,1,1\n",
    "\n",
    "sample_train_gen = create_gen(sample_train_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "sample_valid_gen = create_gen(sample_valid_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "train_gen = create_gen(train_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "valid_gen = create_gen(valid_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "test_gen = create_gen(test_dir, batch_size=batch_size, shuffle=False, gen=datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create sample train data bottleneck features\n",
    "bottleneck_features_train = model.predict_generator(sample_train_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_sample_train, 'w'),\n",
    "        bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create sample validation data bottleneck features\n",
    "bottleneck_features_valid = model.predict_generator(sample_valid_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_sample_valid, 'w'),bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create train data bottleneck features\n",
    "bottleneck_features_train = model.predict_generator(test_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_train, 'w'),bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create valid data bottleneck features\n",
    "bottleneck_features_valid = model.predict_generator(valid_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_valid, 'w'),bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# create test data bottleneck features\n",
    "bottleneck_features_test = model.predict_generator(test_gen)\n",
    "np.save(open(saved_model_dir + bn_feat_test, 'w'), bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load VGG16 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load the saved VGG features. There are two cells here, one for training on the full training set, and one for training only on the small sample data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Full training set of features and labels\n",
    "test_features = np.load(open(saved_model_dir + bn_feat_test))\n",
    "train_features = np.load(open(saved_model_dir + bn_feat_train))\n",
    "valid_features = np.load(open(saved_model_dir + bn_feat_valid))\n",
    "train_labels = np.array([1] * int(nb_train / 2) + [0] * int(nb_train / 2))\n",
    "valid_labels = np.array([1] * int(nb_valid / 2) + [0] * int(nb_valid / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Small sample set of features and labels\n",
    "# train_features = np.load(open(saved_model_dir + bn_feat_sample_train))\n",
    "# valid_features = np.load(open(saved_model_dir + bn_feat_sample_valid))\n",
    "# train_labels = np.array([1] * int(nb_sample_train / 2) + [0] * int(nb_sample_train / 2))\n",
    "# valid_labels = np.array([1] * int(nb_sample_valid / 2) + [0] * int(nb_sample_valid / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Linear model on VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model is just a single linear layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc1 = Sequential()\n",
    "model_fc1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_fc1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_fc1.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 0.6293 - acc: 0.9494 - val_loss: 0.6063 - val_acc: 0.9528\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 0.3472 - acc: 0.9748 - val_loss: 0.3820 - val_acc: 0.9720\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 0.3231 - acc: 0.9762 - val_loss: 0.4282 - val_acc: 0.9690\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 0.2989 - acc: 0.9786 - val_loss: 0.3564 - val_acc: 0.9744\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.2677 - acc: 0.9811 - val_loss: 0.3521 - val_acc: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb892db4050>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_weights = 'best_weights_fc1.h5'\n",
    "checkpointer = ModelCheckpoint(filepath= saved_model_dir + fc1_weights, \n",
    "                               save_best_only=True)\n",
    "\n",
    "model_fc1.fit(train_features,train_labels,\n",
    "              epochs=5,#nb_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(valid_features,valid_labels),\n",
    "              callbacks=[checkpointer],\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12561574509888887"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log loss on validation set\n",
    "model_fc1.load_weights(saved_model_dir + fc1_weights)\n",
    "pred = model_fc1.predict(valid_features)\n",
    "pred = pred.reshape(pred.shape[0])\n",
    "predictions = pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Final model on VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_fc3 = Sequential()\n",
    "model_fc3.add(MaxPooling2D((2, 2), strides=(2, 2), input_shape=train_features.shape[1:]))\n",
    "model_fc3.add(Flatten())\n",
    "model_fc3.add(Dense(4096, activation='relu'))\n",
    "model_fc3.add(BatchNormalization())\n",
    "model_fc3.add(Dropout(0.5))\n",
    "model_fc3.add(Dense(4096, activation='relu'))\n",
    "model_fc3.add(BatchNormalization())\n",
    "model_fc3.add(Dropout(0.5))\n",
    "model_fc3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_fc3.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 14s 693us/step - loss: 0.2223 - acc: 0.9534 - val_loss: 0.1175 - val_acc: 0.9702\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 14s 697us/step - loss: 0.0821 - acc: 0.9733 - val_loss: 0.0818 - val_acc: 0.9752\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 12s 587us/step - loss: 0.0543 - acc: 0.9829 - val_loss: 0.0824 - val_acc: 0.9778\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 12s 586us/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.1124 - val_acc: 0.9766\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 12s 585us/step - loss: 0.0350 - acc: 0.9904 - val_loss: 0.0892 - val_acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8911c9bd0>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc3_weights = 'best_weights_fc3.h5'\n",
    "checkpointer = ModelCheckpoint(filepath= saved_model_dir + fc3_weights, \n",
    "                               save_best_only=True)\n",
    "\n",
    "model_fc3.fit(train_features,train_labels,\n",
    "              epochs=5,#nb_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(valid_features,valid_labels),\n",
    "              callbacks=[checkpointer],\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Doesn't look like we're seeing much improvement on the loss function after a few epochs. We'd probably need to tweak some hyperparameters or the architecture to improve much from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10920777253806591"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log loss on validation set\n",
    "model_fc3.load_weights(saved_model_dir + fc3_weights)\n",
    "pred = model_fc3.predict(valid_features)\n",
    "pred = pred.reshape(pred.shape[0])\n",
    "predictions = pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like it's an improvement on the linear model above. It's surprising how well the linear model did though. Let's try an ensemble of this model next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    \n",
    "    def __init__(self, nb_models = 3):\n",
    "        self.nb_models = nb_models\n",
    "    \n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2), input_shape=train_features.shape[1:]))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self,epochs=3):\n",
    "        for i in range(self.nb_models):\n",
    "            \n",
    "            weights = 'best_weights_fc3_'+str(i)+'.h5'\n",
    "            checkpointer = ModelCheckpoint(filepath= saved_model_dir + weights, \n",
    "                                           save_best_only=True)\n",
    "            model = self.create_model()\n",
    "            model.fit(train_features,train_labels,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          validation_data=(valid_features,valid_labels),\n",
    "                          callbacks=[checkpointer],\n",
    "                          verbose=1)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        preds = []\n",
    "        model = self.create_model()\n",
    "        for i in range(self.nb_models):\n",
    "            model.load_weights(saved_model_dir + 'best_weights_fc3_'+str(i)+'.h5')\n",
    "            preds.append(model.predict(x))\n",
    "        ens_pred = np.stack(preds).mean(axis=0)\n",
    "        return ens_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_ens = Ensemble(3)\n",
    "model_ens.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097072397928684953"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log log on validation set\n",
    "ens_pred = model_ens.predict(valid_features)\n",
    "ens_pred = ens_pred.reshape(ens_pred.shape[0])\n",
    "predictions = ens_pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 687us/step - loss: 0.2133 - acc: 0.9523 - val_loss: 0.0934 - val_acc: 0.9748\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 12s 575us/step - loss: 0.0794 - acc: 0.9747 - val_loss: 0.1409 - val_acc: 0.9692\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 14s 700us/step - loss: 0.0523 - acc: 0.9847 - val_loss: 0.0838 - val_acc: 0.9776\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 680us/step - loss: 0.2159 - acc: 0.9535 - val_loss: 0.1117 - val_acc: 0.9740\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 691us/step - loss: 0.0863 - acc: 0.9727 - val_loss: 0.0786 - val_acc: 0.9756\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 12s 581us/step - loss: 0.0552 - acc: 0.9824 - val_loss: 0.0822 - val_acc: 0.9784\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 685us/step - loss: 0.1971 - acc: 0.9561 - val_loss: 0.1593 - val_acc: 0.9646\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 686us/step - loss: 0.0835 - acc: 0.9734 - val_loss: 0.1225 - val_acc: 0.9692\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 14s 694us/step - loss: 0.0573 - acc: 0.9829 - val_loss: 0.0972 - val_acc: 0.9766\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 690us/step - loss: 0.2227 - acc: 0.9535 - val_loss: 0.5524 - val_acc: 0.8822\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 692us/step - loss: 0.0855 - acc: 0.9724 - val_loss: 0.0756 - val_acc: 0.9782\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 12s 583us/step - loss: 0.0512 - acc: 0.9843 - val_loss: 0.0993 - val_acc: 0.9710\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 14s 687us/step - loss: 0.2320 - acc: 0.9511 - val_loss: 0.1360 - val_acc: 0.9684\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 14s 691us/step - loss: 0.0854 - acc: 0.9724 - val_loss: 0.1007 - val_acc: 0.9728\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 14s 701us/step - loss: 0.0583 - acc: 0.9812 - val_loss: 0.0872 - val_acc: 0.9742\n"
     ]
    }
   ],
   "source": [
    "model_ens = Ensemble(5)\n",
    "model_ens.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0926154362514615"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log log on validation set\n",
    "ens_pred = model_ens.predict(valid_features)\n",
    "ens_pred = ens_pred.reshape(ens_pred.shape[0])\n",
    "predictions = ens_pred.clip(min=0.05, max=0.95)\n",
    "log_loss(valid_labels,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As usual, an ensemble tends to do better. Adding more models seems to continue the trend. We could also try an ensemble of different types of models, perhaps using different pre-trained model architectures. I think this should be enough to get into the top 40% of the kaggle competition though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## PREPARE KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "iscat_pred = model_ens.predict(test_features)\n",
    "predictions = (1 - iscat_pred).reshape(iscat_pred.shape[0])\n",
    "predictions = predictions.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get file indices\n",
    "generator = create_gen(test_dir, batch_size=batch_size, shuffle=False, gen=datagen)\n",
    "filenames = generator.filenames\n",
    "idx = np.array([int(f[5:f.rfind('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/dogs-v-cats-redux\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "subm = np.stack([idx,predictions],axis=1)\n",
    "submission_file_name = 'submission3.csv'\n",
    "%cd ~/git/dogs-v-cats-redux\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
